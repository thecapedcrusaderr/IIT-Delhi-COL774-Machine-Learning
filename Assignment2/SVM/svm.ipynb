{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "from cvxopt import matrix\n",
    "import statistics\n",
    "from cvxopt import solvers\n",
    "import seaborn as sn\n",
    "from collections import Counter\n",
    "solvers.options['show_progress'] = False\n",
    "from tqdm import tqdm\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"train.csv\",header=None).to_numpy()\n",
    "test=pd.read_csv(\"test.csv\",header=None).to_numpy()\n",
    "validate=pd.read_csv(\"val.csv\",header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3.5\">__Q1 Part A Linear Kernel through CVXOPT__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainLinear(C,class1,class2):\n",
    "    \n",
    "    trainTemp=train[(train[:,-1]==class1) | (train[:,-1]==class2)].copy()#[:,:-1]/255\n",
    "    validateTemp=validate[(validate[:,-1]==class1) | (validate[:,-1]==class2)].copy()#[:,:-1]/255\n",
    "    testTemp=test[(test[:,-1]==class1) | (test[:,-1]==class2)].copy()#[:,:-1]/255\n",
    "    \n",
    "    positiveTrain=trainTemp[(trainTemp[:,-1]==class1)].copy()[:,:-1]/255\n",
    "    negativeTrain=trainTemp[(trainTemp[:,-1]==class2)].copy()[:,:-1]/255\n",
    "    \n",
    "    trainClassOut = trainTemp[:,-1].copy().reshape(-1,1)\n",
    "    validateClassOut = validateTemp[:,-1].copy().reshape(-1,1)\n",
    "    testClassOut = testTemp[:,-1].copy().reshape(-1,1)\n",
    "    \n",
    "    \n",
    "    posIndTrain,negIndTrain=np.where(trainClassOut==class1),np.where(trainClassOut==class2)\n",
    "    posIndTest,negIndTest=np.where(testClassOut==class1),np.where(testClassOut==class2)\n",
    "    posIndVali,negIndVali=np.where(validateClassOut==class1),np.where(validateClassOut==class2)\n",
    "    \n",
    "    \n",
    "    trainClassOut[negIndTrain] = -1\n",
    "    trainClassOut[posIndTrain] = 1 \n",
    "    \n",
    "    \n",
    "    testClassOut[posIndTest],testClassOut[negIndTest]=1,-1\n",
    "    validateClassOut[posIndVali],validateClassOut[negIndVali]=1,-1\n",
    "   \n",
    "    trainClass,testClass,validateClass=trainTemp[:,:-1]/255,testTemp[:,:-1]/255,validateTemp[:,:-1]/255\n",
    "    \n",
    "    \n",
    "    def findAttributes(c):\n",
    "        m=trainClass.shape[0]\n",
    "        q=-np.ones((m,1))\n",
    "        a=trainClassOut.T\n",
    "        b=np.zeros((1,1))\n",
    "        x_Mult=np.dot(trainClass,trainClass.T)\n",
    "        y_Mult=np.dot(trainClassOut,trainClassOut.T)\n",
    "        p=np.multiply(x_Mult,y_Mult) #Calculated the value of p\n",
    "        g=np.append(np.diag(np.ones(m)),np.diag(-np.ones(m)),axis=0)\n",
    "        h=np.append(np.full((m,1),c),np.zeros((m,1))).reshape(2*m,1)\n",
    "\n",
    "        return p,q,g,h,a,b\n",
    "    \n",
    "    mystart=time.time()\n",
    "    \n",
    "    def training():\n",
    "        p,q,g,h,a,b=findAttributes(C)\n",
    "        P=matrix(p,tc='d')\n",
    "        Q=matrix(q,tc='d')\n",
    "        G=matrix(g,tc='d')\n",
    "        H=matrix(h,tc='d')\n",
    "        A=matrix(a,tc='d')\n",
    "        B=matrix(b,tc='d')\n",
    "        solution=solvers.qp(P,Q,G,H,A,B)\n",
    "        return solution\n",
    "    \n",
    "    solution=training()\n",
    "    \n",
    "    #Taking the threshold as 1e-5\n",
    "    #This function will return the support vectors, it takes solution as an attribute. Work for both linear and gaussian kernel.\n",
    "    def support_vectors(solPara):\n",
    "        alpha = np.array(solPara['x'])\n",
    "        \n",
    "        print(\"Number of support vectors are \",sum(alpha>1e-5))\n",
    "        \n",
    "        inputWithAlpha=np.append(trainClass,alpha,axis=1)\n",
    "        inputAlphaOut=np.append(inputWithAlpha,trainClassOut,axis=1) #Here we have combined input with alpha and the corresponding output\n",
    "\n",
    "        combinedVectors=inputAlphaOut[(inputAlphaOut[:,-2]>1e-5)]\n",
    "    #     supportVectors=combinedVectors[:,:-1]\n",
    "        out=combinedVectors\n",
    "        print(\"what is out here in support vector function\")\n",
    "        print(out)\n",
    "        return out\n",
    "\n",
    "    #WE are returning whole output input with alpha with output and then will slice acc to need.\n",
    "    outputFromSupport=support_vectors(solution)\n",
    "    \n",
    "    #score from here, we would get our desired support vector\n",
    "    supportVector=outputFromSupport[:,:-2]\n",
    "    \n",
    "    # print(supportVector)\n",
    "    def findWAndB(): \n",
    "        #Here, we have taken outputFromSupport \n",
    "        alpha=outputFromSupport[:,-2]\n",
    "        alpha=alpha.reshape(alpha.size,1)\n",
    "        y=outputFromSupport[:,-1]\n",
    "        y=y.reshape(y.size,1)\n",
    "        x=outputFromSupport[:,:-2]\n",
    "        temp=np.multiply(np.multiply(alpha,y),x)\n",
    "        out=temp[0]\n",
    "\n",
    "        for vector in temp[1:,:]:\n",
    "    #         print(vector.shape)\n",
    "            out=np.add(out,vector)\n",
    "        #Now here comes the part for b\n",
    "    \n",
    "        wHere=out.reshape(out.size,1) #Taking w for dot product of w and x , w^T * x\n",
    "        positiveOut=min(np.dot(positiveTrain,wHere))\n",
    "        negativeOut=max(np.dot(negativeTrain,wHere))\n",
    "        bHere=-(positiveOut+negativeOut)/2\n",
    "        return out,bHere\n",
    "    \n",
    "\n",
    "    w,b=findWAndB()\n",
    "    print(\"Time my implementation took for linear svm is \", time.time()-mystart)\n",
    "    print(w.shape)\n",
    "    print(b)\n",
    "    \n",
    "    def accuracy():\n",
    "        valiProd=np.dot(validateClass,w)\n",
    "        testProd=np.dot(testClass,w)\n",
    "        trainProd=np.dot(trainClass,w)\n",
    "        valiOut=valiProd+b\n",
    "        testOut=testProd+b\n",
    "        trainOut=trainProd+b\n",
    "        valiFinal=np.array([1 if item>=0 else -1 for item in valiOut]).reshape(-1,1)\n",
    "        testFinal=np.array([1 if item>=0 else -1 for item in testOut]).reshape(-1,1)\n",
    "        trainFinal=np.array([1 if item>=0 else -1 for item in trainOut]).reshape(-1,1)\n",
    "        print(\"Validate Accuracy is \",(np.sum(valiFinal==validateClassOut)/valiFinal.size)*100,\" % \")\n",
    "        print(\"Test Accuracy is \",(np.sum(testFinal==testClassOut)/testFinal.size)*100,\" % \")\n",
    "        print(\"Train Accuracy is \",(np.sum(trainFinal==trainClassOut)/trainFinal.size)*100,\" % \")\n",
    "         \n",
    "    accuracy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.3874e+02 -7.3498e+03  4e+04  2e+00  1e-12\n",
      " 1: -7.8159e+01 -3.6059e+03  7e+03  3e-01  9e-13\n",
      " 2: -2.3151e+01 -8.1591e+02  1e+03  6e-02  6e-13\n",
      " 3: -8.2817e+00 -3.2692e+02  5e+02  2e-02  2e-13\n",
      " 4: -1.9531e+00 -5.9043e+01  9e+01  3e-03  8e-14\n",
      " 5: -6.9181e-01 -1.3465e+01  2e+01  7e-04  3e-14\n",
      " 6: -3.3850e-01 -2.8374e+00  3e+00  1e-04  2e-14\n",
      " 7: -3.3182e-01 -1.0866e+00  8e-01  2e-16  2e-14\n",
      " 8: -4.8517e-01 -8.0175e-01  3e-01  3e-16  2e-14\n",
      " 9: -5.4774e-01 -6.8892e-01  1e-01  2e-16  2e-14\n",
      "10: -5.8820e-01 -6.2264e-01  3e-02  2e-16  2e-14\n",
      "11: -6.0131e-01 -6.0673e-01  5e-03  2e-16  2e-14\n",
      "12: -6.0378e-01 -6.0391e-01  1e-04  2e-16  2e-14\n",
      "13: -6.0384e-01 -6.0384e-01  2e-06  2e-16  2e-14\n",
      "14: -6.0384e-01 -6.0384e-01  2e-08  2e-16  2e-14\n",
      "Optimal solution found.\n",
      "Number of support vectors are  [57]\n",
      "what is out here in support vector function\n",
      "[[ 0.          0.          0.         ...  0.          0.02683546\n",
      "   1.        ]\n",
      " [ 0.          0.          0.30588235 ...  0.          0.00395167\n",
      "   1.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.02556961\n",
      "  -1.        ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.0360116\n",
      "   1.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.07755732\n",
      "   1.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.0423891\n",
      "  -1.        ]]\n",
      "Time my implementation took for linear svm is  54.12275290489197\n",
      "(784,)\n",
      "[0.76385055]\n",
      "Validate Accuracy is  99.8  % \n",
      "Test Accuracy is  100.0  % \n",
      "Train Accuracy is  100.0  % \n"
     ]
    }
   ],
   "source": [
    "mainLinear(1,0,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3.5\">__Q1 Part B Gaussian Kernel through CVXOPT__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainGaussian(C,Gamma,class1,class2):\n",
    "    dummy=time.time()\n",
    "    \n",
    "    trainTemp=train[(train[:,-1]==class1) | (train[:,-1]==class2)].copy()#[:,:-1]/255\n",
    "    validateTemp=validate[(validate[:,-1]==class1) | (validate[:,-1]==class2)].copy()#[:,:-1]/255\n",
    "    testTemp=test[(test[:,-1]==class1) | (test[:,-1]==class2)].copy()#[:,:-1]/255\n",
    "    \n",
    "    positiveTrain=trainTemp[(trainTemp[:,-1]==class1)][:,:-1]/255\n",
    "    negativeTrain=trainTemp[(trainTemp[:,-1]==class2)][:,:-1]/255\n",
    "    \n",
    "    trainClassOut = trainTemp[:,-1].copy().reshape(-1,1)\n",
    "    validateClassOut = validateTemp[:,-1].copy().reshape(-1,1)\n",
    "    testClassOut = testTemp[:,-1].copy().reshape(-1,1)\n",
    "    \n",
    "    \n",
    "    posIndTrain,negIndTrain=np.where(trainClassOut==class1),np.where(trainClassOut==class2)\n",
    "    posIndTest,negIndTest=np.where(testClassOut==class1),np.where(testClassOut==class2)\n",
    "    posIndVali,negIndVali=np.where(validateClassOut==class1),np.where(validateClassOut==class2)\n",
    "    \n",
    "    \n",
    "    trainClassOut[negIndTrain] = -1\n",
    "    trainClassOut[posIndTrain] = 1 \n",
    "    \n",
    "    \n",
    "    testClassOut[posIndTest],testClassOut[negIndTest]=1,-1\n",
    "    validateClassOut[posIndVali],validateClassOut[negIndVali]=1,-1\n",
    "   \n",
    "    trainClass,testClass,validateClass=trainTemp[:,:-1]/255,testTemp[:,:-1]/255,validateTemp[:,:-1]/255\n",
    "\n",
    "    def gaussianAttributes(c,gamma):\n",
    "        m=trainClass.shape[0]\n",
    "\n",
    "        q=-np.ones((m,1))\n",
    "        a=trainClassOut.T\n",
    "        b=np.zeros((1,1))\n",
    "        def findx_Mult():\n",
    "\n",
    "            temp=np.exp((distance.cdist(trainClass,trainClass)**2)*(-1*gamma))\n",
    "            return temp\n",
    "\n",
    "        x_Mult=findx_Mult()\n",
    "\n",
    "        y_Mult=np.dot(trainClassOut,trainClassOut.T)\n",
    "        p=np.multiply(x_Mult,y_Mult) #Calculated the value of p\n",
    "        g=np.append(np.diag(np.ones(m)),np.diag(-np.ones(m)),axis=0)\n",
    "        h=np.append(np.full((m,1),c),np.zeros((m,1))).reshape(2*m,1)\n",
    "\n",
    "        return p,q,g,h,a,b #For gaussian parameters\n",
    "    \n",
    "        # Gamma = 0.05 , c=1.0\n",
    "    start=time.time()\n",
    "    def gaussianTraining():\n",
    "        p,q,g,h,a,b=gaussianAttributes(C,Gamma)\n",
    "\n",
    "        P,Q,G,H,A,B=matrix(p,tc='d'),matrix(q,tc='d'),matrix(g,tc='d'),matrix(h,tc='d'),matrix(a,tc='d'),matrix(b,tc='d')\n",
    "        solution=solvers.qp(P,Q,G,H,A,B)\n",
    "        return solution\n",
    "    \n",
    "    gaussianSolution=gaussianTraining()\n",
    "    \n",
    "    #Taking the threshold as 1e-5\n",
    "    #This function will return the support vectors, it takes solution as an attribute. Work for both linear and gaussian kernel.\n",
    "    def support_vectors(solPara):\n",
    "        alpha = np.array(solPara['x'])\n",
    "#         print(\"alpha kya hai\")\n",
    "        print(\"Number of support vectors are\",sum(alpha>1e-5))\n",
    "\n",
    "        inputWithAlpha=np.append(trainClass,alpha,axis=1)\n",
    "#         print(inputWithAlpha.shape)\n",
    "        inputAlphaOut=np.append(inputWithAlpha,trainClassOut,axis=1) #Here we have combined input with alpha and the corresponding output\n",
    "#         print(inputAlphaOut.shape)\n",
    "        combinedVectors=inputAlphaOut[inputAlphaOut[:,-2]>1e-5]\n",
    "\n",
    "        out=combinedVectors\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def gaussianSupportVectors():\n",
    "        gaussianAttrFromSupport=support_vectors(gaussianSolution)\n",
    "        gaussianSupportVector=gaussianAttrFromSupport[:,:-2] #It will give support vector for gaussian\n",
    "        gaussianAlpha=gaussianAttrFromSupport[:,-2]\n",
    "        # For number of gaussian support vectors\n",
    "#         print(\"Number of gaussian support vectors are \", sum(gaussianAlpha>1e-5)) \n",
    "        return gaussianSupportVector\n",
    "    \n",
    "    gaussianSupportVector=gaussianSupportVectors()\n",
    "#     print(gaussianSupportVector)\n",
    "    \n",
    "    def gaussianReturnParamters(gamma):\n",
    "        #Here we would find b and accuracy thereby\n",
    "        gaussianOutFromSupport=support_vectors(gaussianSolution)\n",
    "        y=gaussianOutFromSupport[:,-1]\n",
    "        alpha=gaussianOutFromSupport[:,-2]\n",
    "        x=gaussianOutFromSupport[:,:-2]\n",
    "\n",
    "\n",
    "        def findB():\n",
    "            #For Positive Max\n",
    "            posXOut,negXOut=[],[]\n",
    "            #isko cdist se handle krna hai\n",
    "\n",
    "            temp1=np.exp((distance.cdist(positiveTrain,x)**2)*-gamma)*(alpha.reshape(1,-1))*(y.reshape(1,-1))\n",
    "#             print(\"temp1 is \",temp1)\n",
    "            minPos=min(temp1.sum(axis=1))\n",
    "            temp2=np.exp((distance.cdist(negativeTrain,x)**2)*-gamma)*(alpha.reshape(1,-1))*(y.reshape(1,-1))\n",
    "#             print(\"temp2 is \",temp2)\n",
    "            maxNeg=max(temp2.sum(axis=1))\n",
    "            \n",
    "\n",
    "            \n",
    "            b=-(minPos+maxNeg)/2\n",
    "            return b\n",
    "\n",
    "        b=findB()\n",
    "        print(\"Total time took for gaussian training is \",time.time()-start)\n",
    "        \n",
    "        return gaussianOutFromSupport,b\n",
    "    alphaAndY,bFinal=gaussianReturnParamters(Gamma)\n",
    "    \n",
    "    return alphaAndY,bFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.3464e+02 -6.8388e+03  3e+04  2e+00  1e-15\n",
      " 1: -7.6690e+01 -3.2910e+03  5e+03  2e-01  1e-15\n",
      " 2: -5.4390e+01 -6.8811e+02  8e+02  3e-02  3e-15\n",
      " 3: -8.6653e+01 -2.4599e+02  2e+02  5e-03  2e-15\n",
      " 4: -1.0255e+02 -1.5246e+02  5e+01  1e-03  1e-15\n",
      " 5: -1.0963e+02 -1.2739e+02  2e+01  3e-04  8e-16\n",
      " 6: -1.1318e+02 -1.1820e+02  5e+00  4e-05  8e-16\n",
      " 7: -1.1445e+02 -1.1556e+02  1e+00  4e-06  8e-16\n",
      " 8: -1.1479e+02 -1.1496e+02  2e-01  5e-07  8e-16\n",
      " 9: -1.1485e+02 -1.1486e+02  5e-03  9e-09  9e-16\n",
      "10: -1.1485e+02 -1.1485e+02  1e-04  2e-10  9e-16\n",
      "Optimal solution found.\n",
      "Number of support vectors are [847]\n",
      "Number of support vectors are [847]\n",
      "Total time took for gaussian training is  42.964749574661255\n",
      "value of b in gaussian is  -0.031048543371928056\n",
      "Validate Accuracy through gaussian kernel is  100.0  % \n",
      "Test Accuracy through gaussian kernel is  100.0  % \n",
      "Train Accuracy through gaussian kernel is  100.0  % \n"
     ]
    }
   ],
   "source": [
    "def gaussianAccuracy(C,class1,class2,gamma):\n",
    "    \n",
    "    trainTemp=train[(train[:,-1]==class1) | (train[:,-1]==class2)].copy()#[:,:-1]/255\n",
    "    validateTemp=validate[(validate[:,-1]==class1) | (validate[:,-1]==class2)].copy()#[:,:-1]/255\n",
    "    testTemp=test[(test[:,-1]==class1) | (test[:,-1]==class2)].copy()#[:,:-1]/255\n",
    "    \n",
    "    positiveTrain=trainTemp[(trainTemp[:,-1]==class1)][:,:-1]/255\n",
    "    negativeTrain=trainTemp[(trainTemp[:,-1]==class2)][:,:-1]/255\n",
    "    \n",
    "    trainClassOut = trainTemp[:,-1].copy().reshape(-1,1)\n",
    "    validateClassOut = validateTemp[:,-1].copy().reshape(-1,1)\n",
    "    testClassOut = testTemp[:,-1].copy().reshape(-1,1)\n",
    "    \n",
    "    \n",
    "    posIndTrain,negIndTrain=np.where(trainClassOut==class1),np.where(trainClassOut==class2)\n",
    "    posIndTest,negIndTest=np.where(testClassOut==class1),np.where(testClassOut==class2)\n",
    "    posIndVali,negIndVali=np.where(validateClassOut==class1),np.where(validateClassOut==class2)\n",
    "    \n",
    "    \n",
    "    trainClassOut[negIndTrain] = -1\n",
    "    trainClassOut[posIndTrain] = 1 \n",
    "    \n",
    "    \n",
    "    testClassOut[posIndTest],testClassOut[negIndTest]=1,-1\n",
    "    validateClassOut[posIndVali],validateClassOut[negIndVali]=1,-1\n",
    "   \n",
    "    trainClass,testClass,validateClass=trainTemp[:,:-1]/255,testTemp[:,:-1]/255,validateTemp[:,:-1]/255\n",
    "    \n",
    "    alphaAndY,b=mainGaussian(C,gamma,class1,class2)\n",
    "    x,y,alpha=alphaAndY[:,:-2],alphaAndY[:,-1],alphaAndY[:,-2]\n",
    "    \n",
    "    print(\"value of b in gaussian is \",b)\n",
    "    \n",
    "    #Now we will use this b to calculate accuracy\n",
    "    trainPredicted,testPredicted,validatePredicted=[],[],[]\n",
    "\n",
    "    temp1=((np.exp((distance.cdist(trainClass,x)**2)*-gamma)*(alpha.reshape(1,-1))*(y.reshape(1,-1))).sum(axis=1))+b\n",
    "    temp2=((np.exp((distance.cdist(testClass,x)**2)*-gamma)*(alpha.reshape(1,-1))*(y.reshape(1,-1))).sum(axis=1))+b\n",
    "    temp3=((np.exp((distance.cdist(validateClass,x)**2)*-gamma)*(alpha.reshape(1,-1))*(y.reshape(1,-1))).sum(axis=1))+b\n",
    "\n",
    "    trainPredicted=np.array([1 if item>=0 else -1 for item in temp1]).reshape(-1,1)\n",
    "    testPredicted=np.array([1 if item>=0 else -1 for item in temp2]).reshape(-1,1)\n",
    "    validatePredicted=np.array([1 if item>=0 else -1 for item in temp3]).reshape(-1,1)\n",
    "\n",
    "    #Now here we will find the gaussian accuracy\n",
    "    print(\"Validate Accuracy through gaussian kernel is \",(np.sum(validatePredicted==validateClassOut)/validatePredicted.size)*100,\" % \")\n",
    "    print(\"Test Accuracy through gaussian kernel is \",(np.sum(testPredicted==testClassOut)/testPredicted.size)*100,\" % \")\n",
    "    print(\"Train Accuracy through gaussian kernel is \",(np.sum(trainPredicted==trainClassOut)/trainPredicted.size)*100,\" % \")\n",
    "\n",
    "gaussianAccuracy(1.0,9,0,0.05)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3.5\">__Q1 Part C Linear & Gaussian Kernel through skLearn__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skLearn(cPara,gammaPara,class1,class2,kernelPara):\n",
    "    \n",
    "    trainTemp=train[(train[:,-1]==class1) | (train[:,-1]==class2)].copy()#[:,:-1]/255\n",
    "    validateTemp=validate[(validate[:,-1]==class1) | (validate[:,-1]==class2)].copy()#[:,:-1]/255\n",
    "    testTemp=test[(test[:,-1]==class1) | (test[:,-1]==class2)].copy()#[:,:-1]/255\n",
    "    \n",
    "    trainClassOut = trainTemp[:,-1].copy().reshape(-1,1)\n",
    "    validateClassOut = validateTemp[:,-1].copy().reshape(-1,1)\n",
    "    testClassOut = testTemp[:,-1].copy().reshape(-1,1)\n",
    "    \n",
    "    trainClass,testClass,validateClass=trainTemp[:,:-1]/255,testTemp[:,:-1]/255,validateTemp[:,:-1]/255\n",
    "    \n",
    "#     trainClassOut[trainClassOut==class2]=-1\n",
    "#     validateClassOut[validateClassOut==class2]=-1\n",
    "#     testClassOut[testClassOut==class2]=-1\n",
    "#     trainClassOut[trainClassOut==class1]=1\n",
    "#     validateClassOut[validateClassOut==class1]=1\n",
    "#     testClassOut[testClassOut==class1]=1\n",
    "    \n",
    "    start=time.time()\n",
    "    \n",
    "    if kernelPara==\"linear\":\n",
    "        model=SVC(C=cPara,kernel=kernelPara)\n",
    "    else:\n",
    "        model=SVC(C=cPara,gamma=gammaPara,kernel=kernelPara)\n",
    "        \n",
    "    model.fit(trainClass,trainClassOut.ravel())\n",
    "\n",
    "    print(\"Time sklearn svm took is \",time.time()-start)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time sklearn svm took is  0.2569160461425781\n",
      "Number of support vectors are  [24 33]\n",
      "b =  [0.76380279]\n",
      "Train Output through skLearn svm is  100.0  %\n",
      "Test Output through skLearn svm is  100.0  %\n",
      "Validate Output through skLearn svm is  99.8  %\n"
     ]
    }
   ],
   "source": [
    "#This part is for finding gaussian accuracy after the above function returns parameter\n",
    "#In question i had to predict for class 9 and 0\n",
    "\n",
    "def printingsKLrnAccuracies(c,gamma,class1,class2,kernel):\n",
    "\n",
    "    trainTemp=train[(train[:,-1]==class1) | (train[:,-1]==class2)].copy()#[:,:-1]/255\n",
    "    validateTemp=validate[(validate[:,-1]==class1) | (validate[:,-1]==class2)].copy()#[:,:-1]/255\n",
    "    testTemp=test[(test[:,-1]==class1) | (test[:,-1]==class2)].copy()#[:,:-1]/255\n",
    "    \n",
    "    trainClassOut = trainTemp[:,-1].copy().reshape(-1,1)\n",
    "    validateClassOut = validateTemp[:,-1].copy().reshape(-1,1)\n",
    "    testClassOut = testTemp[:,-1].copy().reshape(-1,1)\n",
    "    \n",
    "    trainClass,testClass,validateClass=trainTemp[:,:-1]/255,testTemp[:,:-1]/255,validateTemp[:,:-1]/255\n",
    "\n",
    "# We will uncomment below things to get value of b else it is working just fine.    \n",
    "#     trainClassOut[trainClassOut==class2]=-1\n",
    "#     validateClassOut[validateClassOut==class2]=-1\n",
    "#     testClassOut[testClassOut==class2]=-1\n",
    "#     trainClassOut[trainClassOut==class1]=1\n",
    "#     validateClassOut[validateClassOut==class1]=1\n",
    "#     testClassOut[testClassOut==class1]=1\n",
    "    \n",
    "    model=skLearn(c,gamma,class1,class2,kernel)\n",
    "    trainPredicted,testPredicted,validatePredicted=model.predict(trainClass),model.predict(testClass),model.predict(validateClass)\n",
    "    \n",
    "# Commenting these we are generalizing the code to be used in Q2 Part B\n",
    "#     print('w = ',model.coef_)\n",
    "    print(\"Number of support vectors are \",model.n_support_)\n",
    "    print('b = ',model.intercept_)\n",
    "    print(\"Train Output through skLearn svm is \", accuracy_score(trainClassOut,trainPredicted)*100,\" %\")\n",
    "    print(\"Test Output through skLearn svm is \", accuracy_score(testClassOut,testPredicted)*100,\" %\")\n",
    "    print(\"Validate Output through skLearn svm is \", accuracy_score(validateClassOut,validatePredicted)*100,\" %\")\n",
    "\n",
    "#Fourth attribute is for type of kernel, \"linear\" for linear kernel, \"rbf\" for gaussian kernel\n",
    "# skLearn(1.0,0.05,9,0,\"linear\")\n",
    "printingsKLrnAccuracies(1.0,0.05,0,9,\"linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Time sklearn linear svm took is  0.22699189186096191__\n",
    "\n",
    "__Number of support vectors for linear svm are 57__\n",
    "\n",
    "__Value of b for linear svm is -0.76384274__\n",
    "\n",
    "__Test Accuracy, Validate Accuracy obtained are 100.0% , 99.8%__\n",
    "\n",
    "__Time sklearn Gaussian svm took is 3.4515771865844727__\n",
    "\n",
    "__Number of support vectors for gaussian svm are 826__\n",
    "\n",
    "__Value of b for gaussian svm is -0.18758554__\n",
    "\n",
    "__Test Accuracy, Validate Accuracy obtained are 99.8% , 100%__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiClassCVXOPT(cPara,gammaPara):\n",
    "    \n",
    "    xAlphaY,b=[],[]\n",
    "    \n",
    "    #Here, we are training the model\n",
    "    \n",
    "    for class1 in tqdm(range(10)):\n",
    "        for class2 in tqdm(range(class1+1,10)):\n",
    "            xAlphaYTemp,bTemp=mainGaussian(cPara,gammaPara,class1,class2)\n",
    "            xAlphaY.append(xAlphaYTemp)\n",
    "            b.append(bTemp)\n",
    "               \n",
    "#     with open('xAlphaY','wb') as f:\n",
    "#         pickle.dump(xAlphaY,f)\n",
    "        \n",
    "#     with open('bCVXOTP','wb') as f:\n",
    "#         pickle.dump(b,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiClassCVXOPT(1.0,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xAlphaY ka shape \n",
      "(45,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [02:42,  3.61s/it]\n",
      "100%|██████████| 10/10 [00:00<00:00, 109.28it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 69038.63it/s]\n",
      "100%|██████████| 2500/2500 [00:00<00:00, 63572.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Output through Multi Class svm is  85.08  %\n",
      "Validate Output through Mulit Class svm is  84.96000000000001  %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#After we got our required parameters from our learned model\n",
    "def multiClassPrediction(C,gamma):\n",
    "    \n",
    "#     with open('xAlphaY','rb') as f:\n",
    "#         xAlphaY=pickle.load(f)\n",
    "        \n",
    "#     with open('bCVXOTP','rb') as f:\n",
    "#         b=pickle.load(f)\n",
    "    \n",
    "    xAlphaY=np.asarray(xAlphaY)\n",
    "\n",
    "    print(\"xAlphaY ka shape \")\n",
    "    print(xAlphaY.shape)\n",
    "    \n",
    "    trainClass=train[:,:-1]/255\n",
    "    validateClass=validate[:,:-1]/255\n",
    "    testClass=test[:,:-1]/255\n",
    "    trainClassOut=train[:,-1].reshape(-1,1)\n",
    "    validateClassOut=validate[:,-1].reshape(-1,1)\n",
    "    testClassOut=test[:,-1].reshape(-1,1)    \n",
    "    \n",
    "    validatePredicted,testPredicted,trainPredicted,trainScore,testScore,validateScore=[],[],[],[],[],[]\n",
    "    for (xAY,B) in tqdm(zip(xAlphaY,b)):\n",
    "\n",
    "        x,y,alpha=xAY[:,:-2],xAY[:,-1],xAY[:,-2]\n",
    "        \n",
    "        \n",
    "#         temp1=((np.exp((distance.cdist(trainClass,x)**2)*-gamma)*(alpha.reshape(1,-1))*(y.reshape(1,-1))).sum(axis=1))+B\n",
    "        temp2=((np.exp((distance.cdist(testClass,x)**2)*-gamma)*(alpha.reshape(1,-1))*(y.reshape(1,-1))).sum(axis=1))+B\n",
    "        temp3=((np.exp((distance.cdist(validateClass,x)**2)*-gamma)*(alpha.reshape(1,-1))*(y.reshape(1,-1))).sum(axis=1))+B\n",
    "#         trainScore.append(temp1)\n",
    "        testScore.append(temp2)\n",
    "        validateScore.append(temp3)\n",
    "#         break\n",
    "    k=0\n",
    "    \n",
    "#     trainSumScore=np.zeros((trainClass.shape[0],10))\n",
    "    testSumScore=np.zeros((testClass.shape[0],10))\n",
    "    validateSumScore=np.zeros((validateClass.shape[0],10))\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(10)):\n",
    "        for j in range(i+1,10):    \n",
    "#             trainPredicted.append([i if item>=0 else j for item in trainScore[k]])\n",
    "            testPredicted.append([i if item>=0 else j for item in testScore[k]])\n",
    "            validatePredicted.append([i if item>=0 else j for item in validateScore[k]])\n",
    "            k+=1\n",
    "#             break\n",
    "#         break    \n",
    "        \n",
    "    #Score to sum krna padega na re\n",
    "    trainScore,testScore,validateScore=np.array(trainScore).T,np.array(testScore).T,np.array(validateScore).T \n",
    "    trainPredicted,testPredicted,validatePredicted=np.array(trainPredicted).T,np.array(testPredicted).T,np.array(validatePredicted).T\n",
    "    \n",
    "#     for i in range(len(trainPredicted)):\n",
    "#         for j in range(len(trainPredicted[i])):\n",
    "#             trainSumScore[i,trainPredicted[i,j]]+=abs(trainScore[i,j])\n",
    "            \n",
    "    for i in range(len(testPredicted)):\n",
    "        for j in range(len(testPredicted[i])):\n",
    "            testSumScore[i,testPredicted[i,j]]+=abs(testScore[i,j])\n",
    "    \n",
    "    for i in range(len(validatePredicted)):\n",
    "        for j in range(len(validatePredicted[i])):\n",
    "            validateSumScore[i,validatePredicted[i,j]]+=abs(validateScore[i,j])\n",
    "            \n",
    "    #yahan saare score store kar liye\n",
    "    \n",
    "#     print(\"printing trainPredicted for trainPredicted\")\n",
    "#     print(trainPredicted)\n",
    "    \n",
    "    trainFinal,validateFinal,testFinal=[],[],[]\n",
    "\n",
    "#     for i in tqdm(range(len(trainPredicted))):\n",
    "        \n",
    "#         highest,itemsWithHighFrequency=np.argmax(np.bincount(trainPredicted[i])),[]\n",
    "#         frequency = Counter(trainPredicted[i])\n",
    "#         value = frequency[highest]\n",
    "#         for element,occurence in frequency.items():\n",
    "#             if occurence==value:\n",
    "#                 itemsWithHighFrequency.append(element)\n",
    "        \n",
    "#         if len(itemsWithHighFrequency)==1:\n",
    "#             trainFinal.append(itemsWithHighFrequency[0])\n",
    "#         else:\n",
    "#             maxm,maxmScore=itemsWithHighFrequency[0],trainSumScore[i,itemsWithHighFrequency[0]]\n",
    "#             for l in range(1,len(itemsWithHighFrequency)):\n",
    "#                 if trainSumScore[i,itemsWithHighFrequency[l]] > maxmScore:\n",
    "#                     maxmScore = trainSumScore[i,itemsWithHighFrequency[l]]\n",
    "#                     maxm = itemsWithHighFrequency[l]\n",
    "                    \n",
    "#             trainFinal.append(maxm)\n",
    "    \n",
    "    #For Test Prediction\n",
    "            \n",
    "    for i in tqdm(range(len(testPredicted))):\n",
    "        highest,itemsWithHighFrequency=np.argmax(np.bincount(testPredicted[i])),[]\n",
    "        frequency = Counter(testPredicted[i]) \n",
    "        value = frequency[highest]\n",
    "        \n",
    "        for element,occurence in frequency.items():\n",
    "            if occurence==value:\n",
    "                itemsWithHighFrequency.append(element)\n",
    "        \n",
    "        if len(itemsWithHighFrequency)==1:\n",
    "            testFinal.append(itemsWithHighFrequency[0])\n",
    "        else:\n",
    "            \n",
    "            maxm,maxmScore=itemsWithHighFrequency[0],testSumScore[i,itemsWithHighFrequency[0]]\n",
    "            for l in range(1,len(itemsWithHighFrequency)):\n",
    "                if testSumScore[i,itemsWithHighFrequency[l]] > maxmScore:\n",
    "                    maxmScore = testSumScore[i,itemsWithHighFrequency[l]]\n",
    "                    maxm = itemsWithHighFrequency[l]\n",
    "                    \n",
    "            testFinal.append(maxm)\n",
    "        \n",
    "    #For validate Prediction\n",
    "            \n",
    "    for i in tqdm(range(len(validatePredicted))):\n",
    "        highest,itemsWithHighFrequency=np.argmax(np.bincount(validatePredicted[i])),[]\n",
    "        frequency = Counter(validatePredicted[i]) \n",
    "        value = frequency[highest]\n",
    "        \n",
    "        for element,occurence in frequency.items():\n",
    "            if occurence==value:\n",
    "                itemsWithHighFrequency.append(element)\n",
    "        \n",
    "        if len(itemsWithHighFrequency)==1:\n",
    "            validateFinal.append(itemsWithHighFrequency[0])\n",
    "        else:\n",
    "            \n",
    "            maxm,maxmScore=itemsWithHighFrequency[0],validateSumScore[i,itemsWithHighFrequency[0]]\n",
    "            for l in range(1,len(itemsWithHighFrequency)):\n",
    "                if validateSumScore[i,itemsWithHighFrequency[l]] > maxmScore:\n",
    "                    maxmScore = validateSumScore[i,itemsWithHighFrequency[l]]\n",
    "                    maxm = itemsWithHighFrequency[l]\n",
    "                    \n",
    "            validateFinal.append(maxm)\n",
    "        \n",
    "#     print(\"Train Output through Multi Class svm is \", accuracy_score(trainClassOut,trainFinal)*100,\" %\")\n",
    "    print(\"Test Output through Multi Class svm is \", accuracy_score(testClassOut,testFinal)*100,\" %\")\n",
    "    print(\"Validate Output through Mulit Class svm is \", accuracy_score(validateClassOut,validateFinal)*100,\" %\")\n",
    "    \n",
    "    return testFinal,validateFinal\n",
    "    \n",
    "testPredPackage,validatePredPackage = multiClassPrediction(1.0,0.05)\n",
    "# Here we are returning testPredicted and validatePredicted to be used for confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Train Output through Multi Class svm is  96.52  %__\n",
    "\n",
    "__Test Output through Multi Class svm is  85.08  %__\n",
    "\n",
    "__Validate Output through Mulit Class svm is  84.96000000000001  %__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [09:08<00:00, 12.20s/it]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 65535.39it/s]\n",
      "100%|██████████| 2500/2500 [00:00<00:00, 68264.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Output through Multi Class svm is  88.08  %\n",
      "Validate Output through Mulit Class svm is  87.88  %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def SVMMultiClass():\n",
    "    \n",
    "    trainClass=train[:,:-1]/255\n",
    "    validateClass=validate[:,:-1]/255\n",
    "    testClass=test[:,:-1]/255\n",
    "    trainClassOut=train[:,-1].reshape(-1,1)\n",
    "    validateClassOut=validate[:,-1].reshape(-1,1)\n",
    "    testClassOut=test[:,-1].reshape(-1,1) \n",
    "    \n",
    "# Here, we have trained different models and stored it using pickle. We would simply load it further computation.\n",
    "\n",
    "#     models=[]\n",
    "    \n",
    "#     classes = [(i,j) for p,(i,j) in enumerate((i,j) for i in range(10) for j in range(i+1,10))]\n",
    "    \n",
    "#     for (class1,class2) in tqdm(classes):        \n",
    "#         models.append(skLearn(1.0,0.05,class1,class2,\"rbf\"))\n",
    "    \n",
    "#     with open('skLrnGaussian','wb') as f:\n",
    "#         pickle.dump(models,f)\n",
    "        \n",
    "#     with open('skLrnGaussian','rb') as f:\n",
    "#         models=pickle.load(f)\n",
    "      \n",
    "    trainPredLabel,testPredLabel,valiPredLabel=[],[],[]\n",
    "    trainScore,testScore,valiScore=[],[],[]\n",
    "    \n",
    "    for model in tqdm(models):\n",
    "#         trainPredLabel.append(model.predict(trainClass))\n",
    "#         trainScore.append(model.decision_function(trainClass))\n",
    "        testPredLabel.append([int(x) for x in model.predict(testClass)])\n",
    "        testScore.append(model.decision_function(testClass))\n",
    "        valiPredLabel.append([int(x) for x in model.predict(validateClass)])\n",
    "        valiScore.append(model.decision_function(validateClass))\n",
    "#         break\n",
    "    \n",
    "    \n",
    "#     print(\"testPredLabel ka type\",type(testPredLabel))\n",
    "#     print(testPredLabel[0])\n",
    "    \n",
    "#     trainPredLabel,trainScore=np.array(trainPredLabel).T,np.array(trainScore).T\n",
    "    testPredLabel,testScore=np.array(testPredLabel).T,np.array(testScore).T\n",
    "    valiPredLabel,valiScore=np.array(valiPredLabel).T,np.array(valiScore).T\n",
    "    \n",
    "#     print(\"after taking transpose checking for testPredLabel\")\n",
    "#     print(testPredLabel[0])\n",
    "\n",
    "\n",
    "#     trainSumScore=np.zeros((trainClass.shape[0],10))\n",
    "    testSumScore=np.zeros((testClass.shape[0],10))\n",
    "    validateSumScore=np.zeros((validateClass.shape[0],10))\n",
    "    \n",
    "#     for i in range(len(trainPredLabel)):\n",
    "#         for j in range(len(trainPredLabel[i])):\n",
    "#             trainSumScore[i,trainPredLabel[i,j]]+=abs(trainScore[i,j])\n",
    "    \n",
    "    \n",
    "#     print(\"printing length of testPredLabel \",len(testPredLabel))\n",
    "    \n",
    "    for i in range(len(testPredLabel)):\n",
    "        for j in range(len(testPredLabel[i])):\n",
    "            testSumScore[i,testPredLabel[i,j]]+=abs(testScore[i,j])\n",
    "    \n",
    "    for i in range(len(valiPredLabel)):\n",
    "        for j in range(len(valiPredLabel[i])):\n",
    "            validateSumScore[i,valiPredLabel[i,j]]+=abs(valiScore[i,j])\n",
    "            \n",
    "    #yahan saare score store kar liye\n",
    "    \n",
    "#     print(\"printing trainPredicted for trainPredicted\")\n",
    "#     print(trainPredicted)\n",
    "    \n",
    "    trainFinal,validateFinal,testFinal=[],[],[]\n",
    "\n",
    "#     for i in tqdm(range(len(trainPredLabel))):\n",
    "        \n",
    "#         highest,itemsWithHighFrequency=np.argmax(np.bincount(trainPredLabel[i])),[]\n",
    "#         frequency = Counter(trainPredLabel[i])\n",
    "#         value = frequency[highest]\n",
    "#         for element,occurence in frequency.items():\n",
    "#             if occurence==value:\n",
    "#                 itemsWithHighFrequency.append(element)\n",
    "        \n",
    "#         if len(itemsWithHighFrequency)==1:\n",
    "#             trainFinal.append(itemsWithHighFrequency[0])\n",
    "#         else:\n",
    "#             maxm,maxmScore=itemsWithHighFrequency[0],trainSumScore[i,itemsWithHighFrequency[0]]\n",
    "#             for l in range(1,len(itemsWithHighFrequency)):\n",
    "#                 if trainSumScore[i,itemsWithHighFrequency[l]] > maxmScore:\n",
    "#                     maxmScore = trainSumScore[i,itemsWithHighFrequency[l]]\n",
    "#                     maxm = itemsWithHighFrequency[l]\n",
    "                    \n",
    "#             trainFinal.append(maxm)\n",
    "    \n",
    "    #For Test Prediction\n",
    "            \n",
    "    for i in tqdm(range(len(testPredLabel))):\n",
    "        highest,itemsWithHighFrequency=np.argmax(np.bincount(testPredLabel[i])),[]\n",
    "        frequency = Counter(testPredLabel[i]) \n",
    "        value = frequency[highest]\n",
    "        \n",
    "        for element,occurence in frequency.items():\n",
    "            if occurence==value:\n",
    "                itemsWithHighFrequency.append(element)\n",
    "        \n",
    "        if len(itemsWithHighFrequency)==1:\n",
    "            testFinal.append(itemsWithHighFrequency[0])\n",
    "        else:\n",
    "            \n",
    "            maxm,maxmScore=itemsWithHighFrequency[0],testSumScore[i,itemsWithHighFrequency[0]]\n",
    "            for l in range(1,len(itemsWithHighFrequency)):\n",
    "                if testSumScore[i,itemsWithHighFrequency[l]] > maxmScore:\n",
    "                    maxmScore = testSumScore[i,itemsWithHighFrequency[l]]\n",
    "                    maxm = itemsWithHighFrequency[l]\n",
    "                    \n",
    "            testFinal.append(maxm)\n",
    "        \n",
    "    #For validate Prediction\n",
    "            \n",
    "    for i in tqdm(range(len(valiPredLabel))):\n",
    "        highest,itemsWithHighFrequency=np.argmax(np.bincount(valiPredLabel[i])),[]\n",
    "        frequency = Counter(valiPredLabel[i]) \n",
    "        value = frequency[highest]\n",
    "        \n",
    "        for element,occurence in frequency.items():\n",
    "            if occurence==value:\n",
    "                itemsWithHighFrequency.append(element)\n",
    "        \n",
    "        if len(itemsWithHighFrequency)==1:\n",
    "            validateFinal.append(itemsWithHighFrequency[0])\n",
    "        else:\n",
    "            \n",
    "            maxm,maxmScore=itemsWithHighFrequency[0],validateSumScore[i,itemsWithHighFrequency[0]]\n",
    "            for l in range(1,len(itemsWithHighFrequency)):\n",
    "                if validateSumScore[i,itemsWithHighFrequency[l]] > maxmScore:\n",
    "                    maxmScore = validateSumScore[i,itemsWithHighFrequency[l]]\n",
    "                    maxm = itemsWithHighFrequency[l]\n",
    "                    \n",
    "            validateFinal.append(maxm)\n",
    "        \n",
    "#     print(\"Train Output through Multi Class svm is \", accuracy_score(trainClassOut,trainFinal)*100,\" %\")\n",
    "    print(\"Test Output through Multi Class svm is \", accuracy_score(testClassOut,testFinal)*100,\" %\")\n",
    "    print(\"Validate Output through Mulit Class svm is \", accuracy_score(validateClassOut,validateFinal)*100,\" %\")\n",
    "    \n",
    "    return testFinal,validateFinal\n",
    "\n",
    "testPredSklearn,validatePredSklearn=SVMMultiClass()\n",
    "# Here we are returning testPredicted and validatePredicted to be used for confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Test Output through Multi Class Svm is 88.08 %__\n",
    "\n",
    "__Validate Output through Mulit Class svm is  87.88  %__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3.5\">__Q2 Part C Confusion Matrix__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "def confusionMatrix(predictionParameter,actualParameter):\n",
    "    \n",
    "    predictionParameter=np.array(predictionParameter)\n",
    "    paraConfusionMatrix = np.zeros((10,10),dtype=int).tolist()\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            if i==j:\n",
    "                paraConfusionMatrix[i][j]=np.sum(np.logical_and(actualParameter==predictionParameter,actualParameter==i))\n",
    "            else:\n",
    "                paraConfusionMatrix[i][j]=np.sum(np.logical_and(actualParameter==j, predictionParameter==i))\n",
    "     \n",
    "    plt.figure(figsize= (7,5))\n",
    "    \n",
    "    sn.heatmap(paraConfusionMatrix,cmap='YlOrBr', annot=True,cbar=False,fmt='d')\n",
    "    \n",
    "#     plt.title(\"Confusion Matrix\", fontsize = 25)\n",
    "    plt.xlabel(\"Actual Class\", fontsize = 20)\n",
    "    plt.ylabel(\"Predicted Class\", fontsize = 20)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "testActual=np.array([int(item) for item in test[:,-1]])\n",
    "validateActual=np.array([int(item) for item in validate[:,-1]])\n",
    "\n",
    "#This function takes two arguments one for test and validation and it will give confusion matrix.\n",
    "#pass the values for all four plots:-testPredPackage,validatePredPackage,testPredSklearn,validatePredSklearn\n",
    "\n",
    "confusionMatrix(validatePredSklearn,validateActual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3.5\">__Q2 Part D K-Fold Cross Validation__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Parallelized this portion of assignment for better \n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from joblib import Parallel, delayed\n",
    "def kFoldCrossVal():\n",
    "    \n",
    "    trainData,testData=train[:,:-1]/255 ,test[:,:-1]/255\n",
    "    trainOut,testOut=train[:,-1],test[:,-1]\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=5)\n",
    "    \n",
    "#     value of c to be taken as \n",
    "    cList=[ 1e-5, 0.001, 1, 5, 10]\n",
    "    outputList=[]\n",
    "    \n",
    "    for c in tqdm(cList):\n",
    "        result=[]\n",
    "        model=SVC(C=c,gamma=0.05,kernel=\"rbf\")\n",
    "        result.append(cross_val_score(model, trainData, trainOut, cv=kfold, n_jobs=-1))\n",
    "        outputList.append(sum(result)/len(result))\n",
    "    return  outputList\n",
    "        \n",
    "# out = Parallel(n_jobs=5, verbose=10)(delayed(kFoldCrossVal)(c) for c in tqdm([1e-5, 1e-3,1,5,10]))    \n",
    "\n",
    "crossValidationAccuracy = kFoldCrossVal()\n",
    "# crossValidationAccuracy,testAccuracy=zip(*out)\n",
    "print(crossValidationAccuracy)\n",
    "\n",
    "with open('crossValidateAccuracy','wb') as f:\n",
    "        pickle.dump(crossValidationAccuracy,f)\n",
    "        \n",
    "# with open('kFoldTestAccuracy','wb') as f:\n",
    "#     pickle.dump(testAccuracy,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now this is for the test Set Accuracies\n",
    "from joblib import Parallel, delayed\n",
    "def testAccuSkLearn(c):\n",
    "  \n",
    "  trainData = train[:,:-1]/255\n",
    "  testData = test[:,:-1]/255\n",
    "  trainOut = train[:,-1]\n",
    "  testOut = test[:,-1]\n",
    "  modelTest = SVC(C=c,gamma=0.05,kernel=\"rbf\",decision_function_shape='ovo')\n",
    "  modelTest.fit(trainData,trainOut.ravel())\n",
    "  out = modelTest.score(testData,testOut)\n",
    "  print(out)\n",
    "  return out\n",
    "\n",
    "testAccuracy = Parallel(n_jobs=5)(delayed(testAccuSkLearn)(c) for c in tqdm([1e-5, 1e-3,1,5,10]))\n",
    "print(testAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For different values of c these are test accuracies we got __\n",
    "\n",
    "__[0.5736, 0.5736, 0.8808, 0.8828, 0.8824]__\n",
    "\n",
    "__For different values of c these are validation accuracies we got__\n",
    "\n",
    "__[0.5664444444444444, 0.5664444444444444, 0.8787111111111111, 0.8844, 0.8842666666666666]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.      -3.       0.       0.69897  1.     ]\n",
      "[-4.88    -2.88     0.12     0.81897  1.12   ]\n"
     ]
    }
   ],
   "source": [
    "def plotting():\n",
    "    #Plotting For cross fold validation and test set accuracies\n",
    "    %matplotlib qt\n",
    "    crossValidateAccuracy = (56.65, 56.65, 87.87, 88.44, 88.43)\n",
    "    testAccuracy =          (57.36, 57.36, 88.08, 88.28, 88.24)\n",
    "    \n",
    "    \n",
    "    fig,ax=plt.subplots()\n",
    "    index=np.arange(5)\n",
    "    width=0.12\n",
    "    \n",
    "    axis1 = np.array([math.log(1e-5,10), math.log(1e-3,10), math.log(1,10), math.log(5,10), math.log(10,10)])\n",
    "    axis2 = axis1 + width\n",
    "    \n",
    "    print(axis1)\n",
    "    print(axis2)\n",
    "    \n",
    "    plt1 = plt.bar(axis1,crossValidateAccuracy, width, color='y',label='Cross Validation Accuracy')\n",
    "    plt2 = plt.bar(axis2, testAccuracy, width, color='b',label='Test Set Accuracy')\n",
    "    \n",
    "    plt.xlabel(\"Values of C\")\n",
    "    plt.ylabel(\"Accuracy in percentage\")\n",
    "    \n",
    "#     plt.xticks(index+width,('1e-5', '1e-3', '1', '5', '10'))\n",
    "    \n",
    "    plt.xticks(axis1)\n",
    "    \n",
    "#     ax.set_xticks(index+width)\n",
    "    \n",
    "    ax.set_xlabel(\"Values of log C\")\n",
    "    ax.set_ylabel(\"Accuracy in percentage\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plotting()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
