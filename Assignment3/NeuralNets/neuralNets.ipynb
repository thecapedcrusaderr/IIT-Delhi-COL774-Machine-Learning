{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "train = pd.read_csv('train.csv',header = None).to_numpy()\n",
    "test = pd.read_csv('test.csv',header = None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNets:\n",
    "    \n",
    "    def __init__(self,hiddenLayers,totalOutputClass,noOfFeatures,bSize,eta,activationType,convergenceCriteria,learnType):\n",
    "        self.hiddenLayers = hiddenLayers\n",
    "        self.totalOutputClass = totalOutputClass\n",
    "        self.noOfFeatures = noOfFeatures\n",
    "        self.bSize = bSize\n",
    "        self.deltaJ = [i for i in range(len(hiddenLayers)+1)]\n",
    "        self.outputs = [i for i in range(len(hiddenLayers)+1)]\n",
    "        self.totalHiddenLayers = len(hiddenLayers)\n",
    "        self.totalLayers = len(hiddenLayers)+1\n",
    "        self.eta = eta\n",
    "        self.epoch = 0\n",
    "        self.learnType = learnType\n",
    "        self.activationType = activationType\n",
    "        self.convergenceCriteria = convergenceCriteria\n",
    "    \n",
    "    def initializeWeights(self,xInput):\n",
    "        theta = []\n",
    "        if self.totalHiddenLayers==0:\n",
    "            totalThetas = self.totalOutputClass * (self.noOfFeatures+1)\n",
    "            theta.append(np.random.uniform(-0.1,0.1,totalThetas).reshape(self.totalOutputClass,self.noOfFeatures+1))\n",
    "        else:\n",
    "            theta.append(np.random.uniform(-0.1,0.1,self.hiddenLayers[0]*(self.noOfFeatures+1)).reshape(self.hiddenLayers[0],self.noOfFeatures+1))\n",
    "            for i in range(1,self.totalHiddenLayers):\n",
    "                thetaSize = self.hiddenLayers[i] * (self.hiddenLayers[i-1]+1)\n",
    "                theta.append(np.random.uniform(-0.1,0.1,thetaSize).reshape(self.hiddenLayers[i],(self.hiddenLayers[i-1]+1)))\n",
    "\n",
    "            totalThetas = self.totalOutputClass * (self.hiddenLayers[-1]+1)\n",
    "            theta.append(np.random.uniform(-0.1,0.1,totalThetas).reshape(self.totalOutputClass,(self.hiddenLayers[-1]+1)))\n",
    "        \n",
    "        self.theta = theta\n",
    "        \n",
    "    def costFun(self,predictedY,originalY): #CostFunction or LossFunction\n",
    "        return (np.sum((originalY-predictedY)**2)/(2*originalY.shape[0]))\n",
    "    \n",
    "    def reluDerivate(self,xArray):\n",
    "        return np.heaviside(xArray,0)\n",
    "    \n",
    "    def activation(self,xArray):\n",
    "        if self.activationType == \"sigmoid\":\n",
    "            return (1/(1+np.exp(-xArray)))\n",
    "        if self.activationType == \"relu\":\n",
    "            return np.maximum(0,xArray)\n",
    "    \n",
    "    def oneHotEncoder(self,yInput):\n",
    "        self.oneHotEncodedY =  np.eye(self.totalOutputClass)[yInput]\n",
    "    \n",
    "    def feedForward(self,xInput,batchSize):\n",
    "        intercept =  np.ones((batchSize,1))\n",
    "        xFinally = np.append(intercept,xInput,axis=1)\n",
    "\n",
    "        for j in range(self.totalHiddenLayers):\n",
    "            dotProd = np.dot(xFinally,self.theta[j].T)\n",
    "            out = self.activation(dotProd)\n",
    "            self.outputs[j] = out\n",
    "            xFinally = np.append(intercept,out,axis=1)\n",
    "        \n",
    "        outputLayerDot = np.dot(xFinally,self.theta[self.totalHiddenLayers].T)\n",
    "        self.outputs[self.totalHiddenLayers] = (1/(1+np.exp(-outputLayerDot)))\n",
    "        # We have seperated output layer as it's activation has to be sigmoid irrespective of activation type of hidden layers\n",
    "    \n",
    "    def backPropagation(self,xInputs,yInput):\n",
    "        #For output layer\n",
    "        yJ, oJ = yInput, self.outputs[self.totalLayers-1]\n",
    "        yJMinusoJ, oneMinusoJ = (yJ - oJ) , (1 - oJ)\n",
    "        oJMultiPly = oJ * oneMinusoJ\n",
    "        delJ = oJMultiPly * yJMinusoJ\n",
    "        self.deltaJ[-1] = delJ  \n",
    "\n",
    "        #Now for hidden layers\n",
    "        for j in range(self.totalLayers-2,-1,-1):\n",
    "            if self.activationType == \"sigmoid\": \n",
    "                oJHidden = self.outputs[j]\n",
    "                oJMultiPly = oJHidden * (1-oJHidden)\n",
    "            if self.activationType == \"relu\":\n",
    "                oJMultiPly = self.reluDerivate(self.outputs[j]) #It would calculate derivative of output with netJ\n",
    "                \n",
    "            delJThetaLJProd = np.dot(self.deltaJ[j+1],self.theta[j+1][:,1:])\n",
    "            finalDelta = oJMultiPly * delJThetaLJProd\n",
    "            self.deltaJ[j] = finalDelta \n",
    "    \n",
    "    def updateWeights(self,xInputs): \n",
    "        for j in range(self.totalLayers):\n",
    "            if j != 0:\n",
    "                xPara = self.outputs[j-1]\n",
    "            else:\n",
    "                xPara = xInputs\n",
    "\n",
    "            xWithIntercept = np.append(np.ones((self.bSize,1)),xPara,axis=1)\n",
    "            delThetaJTheta = np.dot(self.deltaJ[j].T,xWithIntercept)/self.bSize\n",
    "            self.theta[j] = self.theta[j] + (self.eta * delThetaJTheta) \n",
    "    \n",
    "    def fit(self,trainX,trainY):\n",
    "        self.oneHotEncoder(trainY)\n",
    "        self.initializeWeights(trainX)\n",
    "        trainData = trainX[:,:self.noOfFeatures]\n",
    "        totalInputs, minmIter = trainData.shape[0], int(trainData.shape[0]/self.bSize)\n",
    "#         print(minmIter)\n",
    "        \n",
    "    #Now we will implement neural Nets using Stochastic Gradient Descent\n",
    "        costInit, costFinal, i ,count = 100000, -100000, 0, 0 \n",
    "\n",
    "        while True:\n",
    "#             if self.epoch == 2000:\n",
    "#                 break\n",
    "            \n",
    "#             print(abs(costInit-costFinal))\n",
    "            if abs(costInit-costFinal) < self.convergenceCriteria:\n",
    "                break\n",
    "\n",
    "            costPara = 0\n",
    "            for l in range(minmIter):\n",
    "\n",
    "                self.feedForward(trainData[i:i+self.bSize,:],self.bSize)\n",
    "                costPara += self.costFun(self.outputs[-1],self.oneHotEncodedY[i:i+self.bSize,:])\n",
    "                self.backPropagation(trainData[i:i+self.bSize,:],self.oneHotEncodedY[i:i+self.bSize,:])\n",
    "                self.updateWeights(trainData[i:i+self.bSize,:])\n",
    "\n",
    "                count+=1\n",
    "                if (count*self.bSize) % totalInputs == 0:\n",
    "                    self.epoch+=1\n",
    "                    if self.learnType == \"adaptive\":  # For Part C \n",
    "                        self.eta = 0.5/np.sqrt(self.epoch)\n",
    "                    \n",
    "#                     print(self.epoch,\" \",abs(costInit-costFinal))\n",
    "\n",
    "                i=(i+self.bSize)%totalInputs\n",
    "\n",
    "            costInit = costFinal\n",
    "            costFinal = costPara/minmIter\n",
    "    \n",
    "    def predict(self,dataInput):\n",
    "        inputSize = dataInput.shape[0]\n",
    "        self.feedForward(dataInput,inputSize)\n",
    "        predictedOutput = self.outputs[-1]\n",
    "        finalPredicted = np.array([np.argmax(predictedOutput[i]) for i in range(predictedOutput.shape[0])])\n",
    "        return finalPredicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(originalY,predictedY):\n",
    "    return np.sum(originalY==predictedY)/predictedY.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "def plottingAccuracy(x,yTrain,yTest):\n",
    "    plt.plot(x,yTrain,label='Train Accuracy')\n",
    "    plt.plot(x,yTest,label = 'Test Accuracy')\n",
    "    plt.xlabel('Number of Hidden Layer Units')\n",
    "    plt.ylabel('Accuracy in (%)')\n",
    "    plt.legend()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plottingTime(x,yTime):\n",
    "    plt.plot(x,yTime,label='Time taken to train')\n",
    "    plt.xlabel('Number of Hidden Layer Units')\n",
    "    plt.ylabel('Time taken to train the network (in secs)')\n",
    "    plt.legend()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddenLayerList = [1,5,50,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAccuracies, testAccuracies, timeToTrain, epochList = [], [], [], []\n",
    "\n",
    "for units in hiddenLayerList:\n",
    "    nn = neuralNets([units],26,784,100,0.1,\"sigmoid\",(1e-5),\"normal\")\n",
    "    start = time.time()\n",
    "    nn.fit(train[:,:-1]/255,train[:,-1])\n",
    "    timeToTrain.append(time.time()-start)\n",
    "    epochList.append(nn.epoch)\n",
    "    predictedTrain, predictedTest = nn.predict(train[:,:-1]/255), nn.predict(test[:,:-1]/255)\n",
    "    trainAccuracies.append((accuracy_score(train[:,-1],predictedTrain)*100))\n",
    "    testAccuracies.append((accuracy_score(test[:,-1],predictedTest)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Train accuracy for different hidden layer units are \")\n",
    "print(trainAccuracies)\n",
    "print(\"Test accuracy for different hidden layer units are \")\n",
    "print(testAccuracies)\n",
    "print(\"Time taken to train models for different hidden layer units are \")\n",
    "print(timeToTrain)\n",
    "print(\"Total number of epochs for different hidden layer units are \")\n",
    "print(epochList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting for Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plottingAccuracy(hiddenLayerList,trainAccuracies,testAccuracies)\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plottingTime(hiddenLayerList,timeToTrain)\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAccuraciesAdap, testAccuraciesAdap, timeToTrainAdap, epochListAdap = [], [], [], []\n",
    "\n",
    "for units in hiddenLayerList:\n",
    "    nnAdap = neuralNets([units],26,784,100,0.1,\"sigmoid\",(1e-5),\"adaptive\")\n",
    "    start = time.time()\n",
    "    nnAdap.fit(train[:,:-1]/255,train[:,-1])\n",
    "    timeToTrainAdap.append(time.time()-start)\n",
    "    epochListAdap.append(nnAdap.epoch)\n",
    "    predictedTrain, predictedTest = nnAdap.predict(train[:,:-1]/255), nnAdap.predict(test[:,:-1]/255)\n",
    "    trainAccuraciesAdap.append((accuracy_score(train[:,-1],predictedTrain)*100))\n",
    "    testAccuraciesAdap.append((accuracy_score(test[:,-1],predictedTest)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train accuracy for different hidden layer units for adaptive learning are \")\n",
    "print(trainAccuraciesAdap)\n",
    "print(\"Test accuracy for different hidden layer units for adaptive learning are \")\n",
    "print(testAccuraciesAdap)\n",
    "print(\"Time taken to train models for different hidden layer units for adaptive learning are \")\n",
    "print(timeToTrainAdap)\n",
    "print(\"Total number of epochs for different hidden layer units for adaptive learning are \")\n",
    "print(epochListAdap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting for Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = plottingAccuracy(hiddenLayerList,trainAccuraciesAdap,testAccuraciesAdap)\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4 = plottingTime(hiddenLayerList,timeToTrainAdap)\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reluNet = neuralNets([100,100],26,784,100,0.1,\"relu\",(1e-5),\"adaptive\")\n",
    "startRelu = time.time()\n",
    "reluNet.fit(train[:,:-1]/255,train[:,-1])\n",
    "print(\"Time taken to train Relu Network is \",time.time()-startRelu)\n",
    "reluTrnPrd, reluTstPrd = reluNet.predict(train[:,:-1]/255), reluNet.predict(test[:,:-1]/255)\n",
    "reluAcc = [accuracy_score(train[:,-1],reluTrnPrd),accuracy_score(test[:,-1],reluTstPrd)]\n",
    "print(\"Train and test accuracy calculated by this network is \")\n",
    "print(reluAcc)\n",
    "print(\"Total number of epoch it took to train the Relu model is \",reluNet.epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yToSend = np.eye(26)[train[:,-1]]\n",
    "print(yToSend.shape)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "relumodel = MLPClassifier(hidden_layer_sizes=(100,100,),activation='relu',batch_size=100,solver='sgd',learning_rate='invscaling',learning_rate_init=0.5,max_iter=2000,momentum=0)\n",
    "relst = time.time()\n",
    "relumodel.fit(train[:,:-1]/255,yToSend)\n",
    "print(\"Time it took to train the MLP relu model is \",time.time()-relst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpReltrainProba = relumodel.predict_log_proba(train[:,:-1]/255)\n",
    "mlpReltestProba = relumodel.predict_log_proba(test[:,:-1]/255)\n",
    "mlpReltrainO = [np.argmax(item) for item in mlpReltrainProba]\n",
    "mlpReltestO = [np.argmax(item) for item in mlpReltestProba]\n",
    "print(\"MLP Relu Train Accuracy is \",accuracy_score(train[:,-1],mlpReltrainO))\n",
    "print(\"MLP Relu Test Accuracy is \",accuracy_score(test[:,-1],mlpReltestO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Iteration relu Model took is \",relumodel.n_iter_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
